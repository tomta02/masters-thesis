---
title: "20250720_finding_cnv_overlaps_v2"
author: "Tatjana"
format: html
editor: visual
---

## Computing CNV overlaps with GenomicRanges - version 2

after chatting w Kristy on 31.07, try out a new strategy for overlapping CNVs that were called using the "spot-based" CNV analysis.

```{r}
library(tidyverse)
library(magrittr)
library(qs)
library(GenomicRanges)
library(tidyverse)
```

```{r}
# test sample of 1 patient
test = read.table("/g/saka/Tatjana/data/data_for_testing_stuff/prelim_cnv_analysis_spotbased/pat40HD_R1_cnvs_extracted_from_mcmc_infcnvobj.cnv", header = TRUE)
```

```{r}
test$width = test$end - test$start
test$width_kb = (test$width)/1000

test_subset_to_keep = grep(paste0("^", "LN0040HD", "_"), test$bc_name)
test_flt = test[test_subset_to_keep, , drop=FALSE]
```

```{r}
gr = GRanges(seqnames = test_flt$chr,
             ranges = IRanges(
               start = test_flt$start,
               end = test_flt$end,
               names = test_flt$cnv_name),
              barcode = test_flt$bc_name,
              state = test_flt$state_mcmc,
              cnv_name = test_flt$cnv_name
             )
```

```{r}
# First, plot size distribution of CNVs found
ggplot(test_flt, aes(x = width_kb)) +
  geom_histogram(binwidth = 1000) +
  theme_minimal() +
  #scale_x_log10() +
  labs(
    title = "CNV sizes",
    x = "cnv size (kb)",
    y = "freq"
  )
```

Disjoin genomic ranges -\> divide sequences found into non-overlapping "chunks"

```{r}
# disjoin. Reverse mapping = true, to keep metadata
dj = disjoin(gr, with.revmap = TRUE)

mcols(dj) = do.call(rbind, 
                    lapply(mcols(dj)$revmap, function(i){
                      data.frame(
                        bc = paste(mcols(gr)$barcode[i], collapse=","),
                        state = paste(mcols(gr)$state[i], collapse=",")
                        )
                      })
                    )

```

Now: count how often each sequence chunk appears in "gr", by running "countOverlaps"

```{r}
ol = countOverlaps(dj, gr)
mcols(dj)$count = ol
```

```{r}
# make df of the data we want to plot
df = data.frame(
  "chr" = dj@seqnames,
  "start" = dj@ranges@start,
  "width_kb" = (dj@ranges@width)/1000,
  "end" = (dj@ranges@start + dj@ranges@width),
  "count" = dj$count)

df = df[order(df$count, decreasing = TRUE),]
```

\
Now, make plots to investigate the counts per chunk for each chromosome

```{r}
chunkfreq = ggplot(df, aes(x = count)) +
  geom_histogram(binwidth = 10) +
  facet_wrap(~ chr, scales = "free_x") +
  theme_minimal()
#ggsave("/g/saka/Tatjana/data/data_for_testing_stuff/LN0040HD_12BV2R_R1_sequence_chunk_frequencies.png", chunkfreq )

chunkfreq
```

```{r}
# combined plot of "counts per bin" across all chromosomes
ggplot(data = df,
       mapping = aes(x = count)) +
  geom_histogram(binwidth = 20) +
  #scale_x_continuous(trans='log10')
  theme_minimal()
```

#### Clean up disjoined genomic ranges

\- remove chunks that appear with very low frequency (most likely noise) - across all chromosomes

```{r}
# ditch "per chromosome removal" strategy as not necessary - as there is not supposed to be CNVs in each chromosome, just keep 25% of fractions with the highest "count" (i.e. they are present in most spots)

# calc 75th percentile (top 25%) threshold
thresh = quantile(mcols(dj)$count, 0.75, na.rm = TRUE)
dj_clean = dj[mcols(dj)$count >= thresh]
```

```{r}
# apply GenomicRanges::reduce to see whether qc/noise removal step was sufficient
red = reduce(dj_clean) #, with.revmap = TRUE)
# 
# mcols(red) = do.call(rbind,
#                      lapply(mcols(red)$revmap, function(i) { 
#                        data.frame(
#                          bc = paste(mcols(dj_clean)$bc[i], collapse=","),
#                          state = paste(mcols(dj_clean)$state[i], collapse=",")
#                          )
#                        })
#                      )


# some states are amp, some del... think about how to deal with this -> do a max vote?
# -> not doing majority vote as of now, will just export as is and brainstorm w Kristy

## DO NOT REDUCE WITH METADATA FOR NOW- just reduce as simple granges object
```

```{r}
# look at all the states of each CNV:
get_states = function(gr_obj) {
  splitstates = strsplit(gr_obj$state, ",")
  allstates = unlist(splitstates)
  summarycounts = table(allstates)
  summarycounts 
}

states_res = lapply(seq_along(red), function(i) {
  get_states(red[i])
})
```

What next?

1.) expand cleaned disjoined fragments (dj_clean), make gtrellis plots with it

```{r}
# extract metadata
expanded_list = lapply(seq_along(dj_clean), function(i) {
  bc_vec = unlist(strsplit(mcols(dj_clean[i])$bc, ","))
  state_vec = unlist(strsplit(mcols(dj_clean[i])$state, ","))

  # repeat geanges row [i] for each barcode
  n = length(bc_vec)
  gr = dj_clean[i]
  gr_expanded = rep(gr, n)

  # updatemetadata
  mcols(gr_expanded)$bc = bc_vec
  mcols(gr_expanded)$state = state_vec

  return(gr_expanded)
})

## combine all into 1 GRanges
dj_clean_expanded = do.call(c, expanded_list)

```

Now, convert expanded reduced granges to bed-style format

```{r}
# first, convert it to df
gr_df = data.frame(
  "chr" = dj_clean_expanded@seqnames,
  "start" = dj_clean_expanded@ranges@start,
  "end" = (dj_clean_expanded@ranges@start + dj_clean_expanded@ranges@width),
  "width" = dj_clean_expanded@ranges@width,
  "width_kb" = (dj_clean_expanded@ranges@width)/1000,
  "strand" = dj_clean_expanded@strand,
  "barcode" = dj_clean_expanded$bc,
  "state" = dj_clean_expanded$state
)
```

```{r}
# Reshape into sparse BED-like format, needed for most plotting libraries 
gr_df_wide = gr_df %>%
  pivot_wider(
    names_from = barcode,
    values_from = state,
    values_fn = list(state = ~paste(., collapse = ",")),
    # fill missing vals with na
    values_fill = NA  
  )
```

```{r}
# save object
write.csv(
  gr_df_wide,
  file = "/g/saka/Tatjana/data/data_for_testing_stuff/20250912_spotbased_cnv_calling_script5_LN0040HD_12BV2R_R1_extracted_from_mcmc_obj.csv",
  row.names = FALSE)
# for doing some visualizations in another script
```
